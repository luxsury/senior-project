import sys, os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

import cv2
import mediapipe as mp
import numpy as np
import tensorflow as tf
from utils.pose_utils import extract_keypoints_from_frame
import time
import json
from PIL import ImageFont, ImageDraw, Image


# ============================================================
# é›†ä¸­ç®¡ç†çš„å¯èª¿åƒæ•¸ã€‘ â€”â€” å»ºè­°ä½ æ‰€æœ‰èª¿æ•´éƒ½åœ¨é€™ä¸€æ®µå®Œæˆ
# ============================================================

SEQ_LEN = 40                     # æ¨¡å‹çœ‹å¤šå°‘å¹€ï¼ˆè¶Šå¤§è¶Šç©©å®šï¼Œä½†åæ‡‰è¶Šæ…¢ï¼‰
confidence_threshold = 0.70      # ä¿¡å¿ƒåº¦ â‰¥ æ­¤å€¼ â†’ å¯åˆ‡æ›å‹•ä½œ
stable_threshold = 0.90          # ä¿¡å¿ƒåº¦ â‰¥ æ­¤å€¼ â†’ è¦–ç‚ºç©©å®šå‹•ä½œ

camera_index = 0                 # æ”å½±æ©Ÿä¾†æº (0å¤–æ¥/1å…§ç½®)
model_complexity = 1             # Mediapipe Pose æ¨¡å‹è¤‡é›œåº¦ï¼š0=å¿«ã€1=ä¸­ç­‰ã€2=æº–ç¢º
draw_pose = True                 # æ˜¯å¦åœ¨ç•«é¢ä¸­é¡¯ç¤ºéª¨æ¶

font_size_main = 108             # ä¸»æ–‡å­—ï¼ˆå‹•ä½œåç¨±ï¼‰å¤§å°
font_size_category = 48          # å‰¯æ¨™ï¼ˆåˆ†é¡ï¼‰æ–‡å­—å¤§å°
font_size_warning = 80           # è­¦å‘Šå­—é«”å¤§å°
font_size_total = 68             # ä¸‹æ–¹ç¸½æ¬¡æ•¸å¤§å°
font_size_small = 28             # å°å­—é«”å¤§å°


# ============================================================
# ä¸­æ–‡æ–‡å­—ç¹ªè£½ï¼ˆPillowï¼‰
# ============================================================
def draw_chinese_text(img, text, pos, color=(255,255,255), size=40, bold=False, outline=0):
    """
    OpenCV åŸç”Ÿä¸æ”¯æ´ä¸­æ–‡ï¼Œä½¿ç”¨ Pillow ç¹ªè£½å¾Œå†è½‰å› ndarrayã€‚
    æ”¯æ´ï¼šæé‚Šã€åŠ ç²—ã€é¡è‰²ã€‚

    img : ndarray BGR frame
    text : é¡¯ç¤ºæ–‡å­—
    pos : (x,y)
    size : å­—é«”å¤§å°
    bold : ç²—é«”æ•ˆæœ
    outline : å¤–æ¡†åšåº¦
    """
    img_pil = Image.fromarray(img)
    draw = ImageDraw.Draw(img_pil)

    # å­—å‹æœå°‹ (Windows / Mac / Linux)
    FONT_PATHS = [
        "/System/Library/Fonts/PingFang.ttc",
        "/Library/Fonts/Arial Unicode.ttf",
        "C:/Windows/Fonts/msjh.ttc",
        "C:/Windows/Fonts/simhei.ttf",
        "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc"
    ]
    font = None
    for fp in FONT_PATHS:
        if os.path.exists(fp):
            font = ImageFont.truetype(fp, size=size)
            break
    if font is None:
        font = ImageFont.load_default()

    x, y = pos

    # æ–‡å­—æé‚Š
    if outline > 0:
        for dx in range(-outline, outline + 1):
            for dy in range(-outline, outline + 1):
                draw.text((x + dx, y + dy), text, font=font, fill=(0,0,0))

    # ç²—é«”æ•ˆæœ
    if bold:
        for dx, dy in [(1,0),(0,1),(-1,0),(0,-1)]:
            draw.text((x + dx, y + dy), text, font=font, fill=color)

    draw.text(pos, text, font=font, fill=color)
    return np.array(img_pil)


# ============================================================
# Mediapipe Pose åˆå§‹åŒ–
# ============================================================
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils

pose = mp_pose.Pose(
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5,
    model_complexity=model_complexity
)


# ============================================================
# è¼‰å…¥æ¨¡å‹ + Normalization scaler + labels.json
# ============================================================

MODEL_DIR = "models"
MODEL_PATH = os.path.join(MODEL_DIR, "pose_sequence_classifier.h5")
SCALER_PATH = os.path.join(MODEL_DIR, "scaler.npz")
LABEL_PATH = os.path.join(MODEL_DIR, "labels.json")

# è®€å–æ¨¡å‹
if not os.path.exists(MODEL_PATH):
    print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆï¼š{MODEL_PATH}")
    exit()

model = tf.keras.models.load_model(MODEL_PATH)
print(f"âœ… æ¨¡å‹å·²è¼‰å…¥ï¼š{MODEL_PATH}")

# Normalization åƒæ•¸
mean, std = None, None
if os.path.exists(SCALER_PATH):
    scaler = np.load(SCALER_PATH)
    mean = scaler['mean']
    std = scaler['std']
    print("âœ… Scaler å·²è¼‰å…¥ï¼ˆmean/stdï¼‰")
else:
    print("âš ï¸ æ‰¾ä¸åˆ° scaler.npzï¼Œæ¨¡å‹æ•ˆèƒ½å¯èƒ½é™ä½")

# è®€å– labels.json
with open(LABEL_PATH, "r") as f:
    idx_to_label = json.load(f)

# ä¸­æ–‡é¡¯ç¤ºå°ç…§
label_zh = {
    "hamstring_sweep": "åŸ·è‰",
    "knee_hugs": "æŠ±è…¿",
    "walking_kicks": "è¸¢è…¿",
    "neutral": "ç„¡å‹•ä½œ/å¾…æ©Ÿä¸­"
}

label_category = {
    "hamstring_sweep": "æš–èº« / è…¿å¾Œå´",
    "knee_hugs": "æš–èº« / è‡€è…¿",
    "walking_kicks": "æš–èº« / å‹•æ…‹è…¿éƒ¨",
    "neutral": "ç„¡å‹•ä½œ / å¾…æ©Ÿ"
}


# ============================================================
# è®€å–æ”å½±æ©Ÿ
# ============================================================
cap = cv2.VideoCapture(camera_index)
if not cap.isOpened():
    print("âŒ ç„¡æ³•é–‹å•Ÿæ”å½±æ©Ÿ")
    exit()

print("ğŸ¥ é–‹å§‹å³æ™‚åµæ¸¬ï¼ˆæŒ‰ Q çµæŸï¼‰...")

# ============================================================
# ç‹€æ…‹è®Šæ•¸åˆå§‹åŒ–ï¼ˆå‹•ä½œç‹€æ…‹æ©Ÿï¼‰
# ============================================================

seq_buffer = []                      # å­˜æ”¾éå» SEQ_LEN å¹€çš„é—œéµé»
fps = 0.0
prev_time = time.time()

total_count = 0                      # æ‰€æœ‰å‹•ä½œç´¯è¨ˆæ¬¡æ•¸
per_label_count = {lbl: 0 for lbl in idx_to_label.values()}  # æ¯å€‹å‹•ä½œè¨ˆæ•¸

in_action = False                    # æ˜¯å¦ç›®å‰ã€Œæ­£åœ¨å‹•ä½œä¸­ã€
current_action = None               # ç•¶å‰å‹•ä½œåç¨±


# é¡è‰²ä¾ä¿¡å¿ƒåº¦é¸æ“‡
def color_by_conf(conf):
    if conf >= stable_threshold:
        return (102, 255, 102)  # ç¶ 
    if conf >= confidence_threshold:
        return (102, 255, 255)  # é»ƒ
    return (80, 80, 255)        # ç´…


# ============================================================
# ä¸»æ¨è«–è¿´åœˆï¼ˆRealtimeï¼‰
# ============================================================
while True:
    ret, frame = cap.read()
    if not ret:
        break

    frame = cv2.flip(frame, 1)  # é¡åƒ
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = pose.process(rgb)
    pose_detected = results.pose_landmarks is not None

    # é è¨­ UI é¡¯ç¤ºå…§å®¹
    action_label_zh = "åµæ¸¬ä¸­..."
    action_category = "--"
    confidence = 0.0
    alert = False
    show_warning = False
    text_color = (102, 255, 102)

    # ===== ç¹ªè£½éª¨æ¶ï¼ˆå¯é—œé–‰ï¼‰=====
    if draw_pose and pose_detected:
        mp_drawing.draw_landmarks(
            frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,
            mp_drawing.DrawingSpec(color=(180,180,180), thickness=2, circle_radius=3),
            mp_drawing.DrawingSpec(color=(51,0,153), thickness=20, circle_radius=2)
        )

    # ===== å–å¾—ç•¶å¹€çš„é—œéµé» =====
    keypoints = extract_keypoints_from_frame(frame)
    seq_buffer.append(keypoints)

    if len(seq_buffer) > SEQ_LEN:
        seq_buffer.pop(0)

    # ===== ç•¶è’é›†åˆ°è¶³å¤ å¹€æ•¸æ™‚ï¼ŒåŸ·è¡Œæ¨¡å‹æ¨è«– =====
    if len(seq_buffer) == SEQ_LEN and pose_detected:

        seq_array = np.array(seq_buffer, dtype=np.float32)

        # Normalization
        if mean is not None and std is not None:
            seq_array = (seq_array - mean) / std

        # å¢åŠ  batch ç¶­åº¦
        seq_input = seq_array.reshape(1, SEQ_LEN, -1)

        # æ¨¡å‹æ¨è«–
        prediction = model.predict(seq_input, verbose=0)
        idx = int(np.argmax(prediction))
        label = idx_to_label[str(idx)]
        confidence = float(np.max(prediction))

        # UI é¡¯ç¤ºå…§å®¹
        action_label_zh = label_zh[label]
        action_category = label_category[label]
        text_color = color_by_conf(confidence)

        if confidence < confidence_threshold:
            alert = True
            show_warning = True

        # ============================================================
        #ã€å‹•ä½œç‹€æ…‹æ©Ÿã€‘â€”â€” ç”¨ä¾†åˆ¤æ–·ã€Œé–‹å§‹å‹•ä½œã€èˆ‡ã€Œå‹•ä½œå®Œæˆã€
        # ============================================================

        # 1. ç•¶ä¿¡å¿ƒåº¦ â‰¥ é–€æª» â†’ æ›´æ–°ç•¶å‰å‹•ä½œ
        if confidence >= confidence_threshold:

            if current_action != label:
                # åµæ¸¬åˆ°æ–°å‹•ä½œ
                current_action = label
                in_action = True
            else:
                # æŒçºŒåŒä¸€å‹•ä½œ
                in_action = True

        # 2. ä¿¡å¿ƒåº¦ < é–€æª» â†’ è¦–ç‚ºã€Œå‹•ä½œçµæŸã€ï¼Œé–‹å§‹è¨ˆæ•¸
        else:
            if in_action and current_action is not None:
                per_label_count[current_action] += 1
                total_count += 1

                # é‡ç½®ç‹€æ…‹
                in_action = False
                current_action = None

    # è‹¥æ ¹æœ¬æ²’çœ‹åˆ°äººé«”
    elif not pose_detected:
        alert = True
        show_warning = True
        in_action = False
        current_action = None

    # ============================================================
    # UI ç¹ªè£½ï¼ˆå‹•ä½œåç¨±ã€åˆ†é¡ã€è¨ˆæ•¸ã€è­¦å‘Šã€FPSï¼‰
    # ============================================================

    # ç•«ç´…æ¡†æç¤ºç”¨æˆ¶èª¿æ•´ä½ç½®
    if alert:
        cv2.rectangle(frame, (0,0), (frame.shape[1], frame.shape[0]), (0,0,255), 18)

    # å‹•ä½œåç¨±
    frame = draw_chinese_text(frame, 
                              f"{action_label_zh} ({confidence:.2f})",
                              (30, 40),
                              color=text_color, size=font_size_main, bold=True, outline=3)

    # å‹•ä½œåˆ†é¡
    frame = draw_chinese_text(frame, 
                              f"åˆ†é¡ï¼š{action_category}",
                              (30, 200),
                              color=(255,255,255), size=font_size_category, bold=True, outline=3)

    # è¨ˆæ•¸
    h = frame.shape[0]
    frame = draw_chinese_text(frame, f"ç¸½æ¬¡æ•¸ï¼š{total_count}",
                              (30, h - 130),
                              color=(102,255,255), size=font_size_total, bold=True, outline=3)

    # æ¯å€‹å‹•ä½œè¨ˆæ•¸
    per_txt = (
        f"åŸ·è‰ï¼š{per_label_count.get('hamstring_sweep',0)}  "
        f"æŠ±è…¿ï¼š{per_label_count.get('knee_hugs',0)}  "
        f"è¸¢è…¿ï¼š{per_label_count.get('walking_kicks',0)}"
    )
    frame = draw_chinese_text(frame, per_txt, (30, h - 50),
                              color=(200,200,200), size=font_size_small)

    # è­¦å‘Šæ–‡å­—
    if show_warning:
        frame = draw_chinese_text(frame, "å‹•ä½œä¸æ˜ / è«‹èª¿æ•´ä½ç½®",
                                  (30, 300),
                                  color=(102,102,255), size=font_size_warning,
                                  bold=True, outline=2)

    # FPS è¨ˆç®—
    now = time.time()
    dt = now - prev_time
    if dt > 0:
        fps = 0.9 * fps + 0.1 * (1 / dt)
    prev_time = now

    cv2.putText(frame, f"FPS: {fps:.1f}",
                (frame.shape[1] - 170, 40),
                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (180,255,180), 2)

    # é¡¯ç¤ºç•«é¢
    cv2.imshow("Pose Recognition", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break


cap.release()
cv2.destroyAllWindows()
print("ğŸ‘‹ çµæŸå³æ™‚åµæ¸¬ã€‚")
